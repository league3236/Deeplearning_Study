{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepDream.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"QBo6JJuQxCem","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":330},"outputId":"3ec2e4c0-0796-4307-c631-d425b15f64b7","executionInfo":{"status":"ok","timestamp":1523618996262,"user_tz":-540,"elapsed":5316,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["!pip install -q matplotlib-venn\n","\n","from matplotlib_venn import venn2\n","_ = venn2(subsets = (3,2,1))"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAbEAAAE5CAYAAAAeMx4EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3VmMXNeBHuD/LnVr6areN7IXNru5\nSyIlWrIkkpIsRrSlkbzC0gQ2krEtIEAmDhI7mQAJjAzykJcgxgQGMsvDAI7jYMAogR1JtlZboiWL\nMkVSlEiRYpPNrZtk70t1de11bx6uSXFnd7NuneX+H1CgljH5q6e6/j7nnsXwPM8DERGRgkzRAYiI\niJaLJUZERMpiiRERkbJYYkREpCyWGBERKYslRkREymKJERGRslhiRESkLJYYEREpiyVGRETKYokR\nEZGyWGJERKQslhgRESmLJUZERMpiiRERkbJYYkREpCyWGBERKYslRkREymKJERGRslhiRESkLJYY\nEREpiyVGRETKYokREZGyWGJERKQslhgRESmLJUZERMpiiRERkbJYYkREpCyWGBERKYslRkREymKJ\nERGRslhiRESkLFt0ANKA6wLF4q1fngcYBmCa/q9XvkzTf0WjQCwGxOP+KxoV/V9GRJJjidHtuS6w\nsACk08D8/PW/5vPB/Lmm6ZfapWJLJID6eqCh4bOX4wTzZxOREgzP8zzRIUgixSIwMeG/xseB6Wkg\nk/GLTEaJBNDU5L+am4GWFv9lcqacKAxYYmFWLgOTk1eXVjotOtWds22gvR3o7PRfHR1AJCI6FREF\ngCUWNtPTwPCw/xodlXeEVU2G4Y/OOjqAFSuAri4+byPSBEtMd8UiMDLil9bIiP9sK+xM0x+hrVoF\n9PUBqZToRES0TCwxHeVywMmTwOnTwNiYvzKQbq652S+zvj6gtVV0GiJaApaYLspl4MwZ4MQJ4Pz5\ncEwTBiGZBPr7gfXr/cUiRCQ1lpjKPM8vrEujrlJJdCK9tLcDGzYAa9b4i0WISDosMRUtLABHjwLH\njwPZrOg0+otEgIEBv9Da20WnIaIrsMRUMjoKHDniTxtyulCM5mZg40Z/upGjMyLhWGKy8zx/qvCj\nj/y9XCSHWAy45x7grrt4agiRQCwxWZXLwOAg8PHHemxA1pXjAJs2+YUWj4tOQxQ6LDHZuC7w6afA\nwYN83qUS2/anGLds8Vc4ElFNsMRkcuoU8MEHwNyc6CS0XKYJrFsH3H+/f64jEQWKJSaD8+eBffv4\nzEsnkQhw773A5s2AZYlOQ6QtlphIk5PAH/7glxjpKZkEPv95f68Z3ZTruXA9F57nwYP/kWTAgG3a\nMAxDcDqSGUtMhHweeP99f+EGhUNHB/Dww6HZZ+Z5HjLFDOYKc0gX0siVcsiX89e9CpUCym75lr+X\nbdpwLAcRM+L/akUQtaJIRBJIRVNIOkmkHP/XeISLa8KGJVZrJ04Ae/cGd5EkyW3NGuChh7R5XuZ5\nHmbyMxhfGMdsfhZz+TnMFeYwX5hHxavUPI9t2kg6STTHm9ESb0FLogWtiVYkInp8vel6LLFaSaeB\nd97h1CH5y/K3bfMXgCgmU8xgfGEc4wvjmFiYwER24rYjKRnE7fjlQluZWonOZCdsk5vVdcASC5rr\n+nu9Dh70934RXdLbCzz6qNSjslKlhPPz5zE8N4zh9DAyxYzoSFVhGiba69qxMrUSXakudCQ7YBq8\nDVxFLLEgTUwAe/b4F1ES3YiEo7Kp7BSG08MYnhvG2MIYXE//I85s08bK1Er0NfZhdeNqRG1emqoK\nllgQPA84dAg4cIBnHNLiCB6VzeXncGL6BE5On0S6EO4TYkzDxMrUSqxuXI3VTasRs2OiI9EtsMSq\nLZsF3nqLz75o6RwH2LGjZsvxs6UshqaHcGL6BCazkzX5M1VjwMDK1EqsbVmLgaYBWCb3/MmGJVZN\nIyN+geVyopOQyjZu9KcYA9gk7Xkezs2dwycTn+B8+vzlPVl0e1ErinUt67CxbSMaY42i49AfscSq\nwXWB/fv9KUSiamhrA3btqto5jMVKEccnj+OTiU9CP11YDSuSK7CxbSP6m/q5IEQwltidymSA3/wG\nGBsTnYR0E4sBO3cC3d3L/i1m87P4ZPwTDE4NouTy5u9qS0QSuKf9Hmxq24SIFREdJ5RYYnfi4kXg\n9deBQkF0EtKVYQCf+xywdeuS/mczuRkcuHgAp2ZOBRSMrhSzY7i7/W7c3X43HIv3y9USS2y5BgeB\n3/2Oqw+pNnp7gccfB6K3Xvo9l5/DgYsHMDQ9xOddAjiWg01tm7C5YzNXNdYIS2w5PvgA+PBD0Sko\nbBoagKeeAurrr/tX6UIaBy8exImpEywvCdimjc0dm7GlYwunGQPGEluKSgV4+21gaEh0EgqrWAx4\n8snLBwkXygXsv7AfxyaPhWJTsmoSkQQ+t+Jz2NC6gafxB4Qltlj5PPDaa1zAQeLZNrzHH8exZA77\nL+xHvszDpGXXEm/Btp5tWJFaITqKdlhiizE7C7z6qn+IL5FghXoHU23A8XoLJ0zuSVRJf1M/tvVs\n46n6VcQSu53paeDll3l1Cgnn2iZmuqLI2J8V13B9AkfNrMBUtFSO5WBbzzasa5HnvEyVscRuZWoK\n+NWvWGAkXK4phqnmMiq4/iaE0WQCH9ksMtX01PfgkVWPIOlUZ0N7WLHEbmZy0i8w7gEjgVzTwGx3\nDPORW08bTtXFsf82/zckH8dy8GDXg9jYtlF0FGWxxG5kYgL49a9ZYCSU/+zLQwmLO2ljpi6OfSwy\nJXWluvD46sf5rGwZWGLXGh/3C6xYFJ2EQsoDMNedwFx06VOE48kEPuTUopLidhw7V+9EV32X6ChK\nYYldiQVGglUiJiZ7Isgby58F4GIPdRkwsHXFVmxdsZX7yhaJJXbJ9DTw4ossMBKmUO9gss1F+QaL\nN5bqREMcpwxOLaqqK9WFnat3Ih6Ji44iPZYY4F9k+ctf+ifSEwmQ6YhjOpmv3pFRBnCkPobzBlfW\nqioRSeCJ/ifQmewUHUVqLLFSyR+BTU2JTkIh5BnAdG/8qr1fVfu9TRMfpmxMGJxdUJVlWHis7zGs\naa7Nbd8qCneJua5/EsfIiOgkFEKubWKi986ef91OxbKwL2UgXYUpShLngZUP4L4V94mOIaVwl9ie\nPcDx46JTUAhVohbGui2UEPwoqRSxsTfhIWdUAv+zKDgbWjdgR+8O3iR9jfCW2IED/ouoxkqJCMZX\neFVZwLFYBcfB7+MllIxwfrvroru+G0/0P8GLN68QzkofHGSBkRCFegdjK6qzAnEposUiHixEQ/oN\nr4+R9AheOv4Sby64Qvje01NTwDvviE5BIZRrjmGsrYQKxEzr1eXz2FLikm3VTeWm8PLgyyyyPwpX\niZVKwJtv+pdbEtVQrimGiaaC8FuX2xdy6PFiQjPQnZvOTeOl4y8hV+JewHCV2J49wNyc6BQUMvnG\nKCaaxRfYJeszJSRgiY5Bd2gmP4OXB18OfZGFp8Q++QQ4dUp0CgqZfEMU4y1FaQoMAKxKBZ/L2+Aa\nD/XN5Gfw0uBLyJbCe8xYOEpsYgLYu1d0CgqZQkMUE60lqQrskkS+gE0uT0zXwWx+Fi8PvoxCOZy3\nbuhfYsWi/xzMdUUnoRApJh2Mt5bgQt73XXcmi3ZwqbYOZvOzeG3oNVTc8D3v17/E3n4bmJ8XnYJC\npBy1MN7hSl1gAAAPuCfjwgnBx0AYjGZG8daZtxC2rb96v3uPHwfOnBGdgkLEtQxMdFuoKHLMk10u\nY2sxKjoGVcmpmVPYOxKuRyf6ltjCAp+DUU15ACZ7oyjW4CipamrI5rDW5f4xXRwZP4KPxz4WHaNm\n9C2x3/2Od4NRTc30xpEz1dyAujqTRyMiomNQlbw/8j5Oz5wWHaMm9CyxwUFgeFh0CgqR9IoE5iPq\n7tcxXA9bsgaX3Wvk7TNvYzY/KzpG4PQrsXye04hUU4V6B7MJ9ffpxIpFDLg8zUMXJbeEN4beQNlV\n4/nsculXYu+9BxTCuV+Caq8SMTHZ5kq4E2x5+rIlrlbUyEx+BnvO7BEdI1B6vVtHRoCTJ0WnoBCZ\n6nZqfiJ9kKxKBZtKXK2ok6GZIRwZPyI6RmD0KTHXBd59V3QKCpH0yoSyCzlupSObQ4PHRR46eX/k\nfYxlxkTHCIQ+JXb0KJBOi05BIZFviGI2rv5zsBvygLsK+nw0EOB6Ln57+rcoVUqio1SdHu/UYhE4\neFB0CgoJ1zIw1VrR5jnYjaTyBXTxyhatzBfn8f7I+6JjVJ0eJXbokL8qkagGZrtiWj0Hu5l12Yom\nHxB0ybHJYxhJj4iOUVXqv0czGeDwYdEpKCTyjVGl94MthVMqYR1PutfOnjN7UKzocxCE+iX2wQe8\nqZlqwjUNTLWE673Wk8kjpsHHBH1mobSA94bfEx2jatR+d05OAidOiE5BITHXFQ/FNOKVTNfF3Vxy\nr53BqUGcmzsnOkZVqF1i7+v3kJLkVKh3kHY0XY14Gy0LOTRxyb123j33rhaneahbYqOjwIULolNQ\nCHgApttEpxBrbckSHYGqLFPM4NDoIdEx7pi6JXZI/S8+qWGhI67c9SrV1pTLIwlbdAyqso9GP0K6\noPb+WjVLbGYGOKfHfC7JzbVNzCbDXWAAAA9YV3ZEp6Aqq3gV5feOqVliH30kOgGFxNyKGCoI14rE\nm2nN5rhSUUNnZs/gwry6j2bUe0dmszzkl2qiHLMx74RjT9hiGK6HdRWe4qGjvcN74XlqnkGjXokd\nPuwf9ksUsNnOCDytD5dauvZsATYM0TGoyqZyUzg1c0p0jGVRq8SKReDYMdEpKARKiQgWLI7CrmVV\nKljNizO1dPCimufPqlVix475RUYUsLl2rsS7ma48nxHqaCY/o+RoTK0SO3pUdAIKgVLc5ijsFqLF\nIjrBUzx0pOJoTJ0Su3ABmJ8XnYJCIN3O0ylup6+ozkcHLd50bhqnZ06LjrEk6rwTBwdFJ6AQKMds\nLNgchd1OQy6HBHiKh44OXDwgOsKSqFFipRJwSr25WlJPuj3C9YiL4QH9FU4p6mg6N63U4cBqlNip\nU0BZ/YMqSW6ubSIT4eWqi9Va4Pekro5OqLP+QI0SO35cdAIKgUxbjPvCliBaLKKe5ylqaXhuWJkz\nFeUvsXTaP7GeKGCZREl0BOX0VHieoo48eMqMxuQvMS7ooBrIN0ZRAktsqVqLnFLU1fHJ40rcNyZ/\nifGcRKqBTKP83woyihWKqPO4SlFHhUoBQ9NDomPcltzfubOz/nQiUYAqjoUsNzcvW4/HVYq6UmFK\nUe4SO3tWdAIKgYXWKJdz3IE2rlLU1kR2AnP5OdExbknuEuPFl1QDCzF+CN+JRKGIOKcUtTU0I/eU\norwlViwCY2OiU5DmynEbRYOHSt+pXo+rFHUl+3MxeUtseJj3hlHgsk388K2GtiInZHU1k5/BdG5a\ndIybkrfE+DyMamAhxmX11VBXyCPqyftxQndG5ita5HzXeR4wMiI6BWnOn0pkiVWFB/TwehZtyTyl\nKGeJjY8DeZ5hR8HiVGJ1NXB9jLbmCnPSTinKWWIXL4pOQCGQi/GG4mpKlfj11NlIWs7ZMTlLbHxc\ndALSnGsaKBgF0TG0Ei0VYcMQHYMCcj59XnSEG2KJUSgVGhxucK42D2gFp2h1dTFzERVXvtG2fCU2\nPw9ks6JTkObySW7ODUJTRb6PFKqOslvG2IJ8e3fle8dxFEY1kI9wVWIQGuT7QZ2qSMbnYvKVGE/p\noIBVIiaX1gekrsivq85kfC4mX4lxJEYBKzTwuU1Q7HIZMQk/Vqg6JrOT0t0xJte7rVIBJidFpyDN\nFeJyve1108ZzFLXlwcNUdkp0jKvI9d08M8PzEilwRZvvsSA1uXJ9rFB1TWQnREe4ilzvttlZ0Qko\nBEomn9sEqb7EHxJ0NpmVa7ZMrhLjLc4UsHLMRgVcQhekeJFX2+hsYoEjsZvjSIwCVqyzRUfQnum6\nSID78HQ1m5+VanGHXCXGkRgFrMhFHTVRx5ueteXBk2pKUa7v6Lk50QlIc6UIn9fUQkKyjxaqrtm8\nPLNm8rzT8nmgwANZKVglkyVWCzGPBwHrbL4wLzrCZfKUGKcSqQYqkGcuX2cxlyWms3RBns9reUqM\nU4kUsErEhAuOxGoh6vGOAJ3NFzkSu14mIzoBaa4c58rEWnEqLDGdcSR2I3weRgErO1wxVyuRCvfi\n6SxfzqNUkePQAHlKLJ8XnYA0V3b4nKZWbJaY9mSZUpSnxDgSo4BVOJtYM6brIsIVilrLlXKiIwBg\niVGIuAaf09RSAvypQWeFihyf2fKUGKcTKWCuyRKrpTqJPl6o+gplltjVOBKjgHEkVltxT56PF6o+\njsSuxRKjgLHEaouTiXorVuS4rUCO91mxyMswl+C1wUH89fvvo1Auoykex3/atQvrWltFx5Keihud\ny5UK/v6X7+D//uYA/td//mdoa0qJjrRoBsKzsOPkgZN47/+8h0qpglgyhl3P70Jrj97fk5xOvBKX\n4y7ahXQaf/nmm/jrr30Nr37ve3hy/Xr8h9deEx1LCa6C94j95d/+P8SjEdExlkWOD5fgzU/P49W/\neRVP/4un8d3/+l1s3L4Rb/z9G6JjBY7TiVfiETWLZpsmfvwnf4Ku+noAwMO9vTg9PS04lRo8qPc+\n+/ZTD+GfPrNddIxlMULyfW1ZFp7+l0+jpbsFANC1vgtTI1OCUwWv4srxQ6Ec04mcSly09mQS7ckk\nAKDsuvjFkSP4R2vWCE5FQdnUv1J0hGULy3RioiGB1VtWX/7704dOo3OgU2Ci2pDlh0KOxBT1Pw4e\nxPa/+RvsP38e//aRR0THkR7fYbUnx4dLbZ09chYHXjmAx//J46KjBM6T5HNbjveZJF8MlfzZ1q14\n/8//HH+2dSv+8T/8A/IlOc4xIwqrEx+cwKt/+yq+/hdfvzy1qDOOxK5kyhFDBUNTU3jv7FkAgGEY\neGbjRiwUizg9MyM4mdzCMbElFzk+4mrj7OGzeOt/voVv/vtvorNf/6lEQJ7pYjnaw5Dji6GC6VwO\n/+6VVzD2x6trDpw/j5LroqehQXAyoquF5Ul3qVDCq3/3Kr76r7+Kli79R2CXGJJ8bsuxsEOSL4YK\nHujuxj9/8EF894UX4HoeHNvGXz39NJLRqOho0jOg1uhgJr2Af/NXuy///V/8t/8N0zTwX/7Vs2ht\nlH+/mCzTTUE7eeAkcvM5/Oq//+qqf/6n//FPUddQJyhV8ExDkjGQJ8PTuXwe+NnPRKcgzQ0P8Gbn\nWjqXSuCYlRUdgwKypnkNdq7eKTqGJNOJETU3c5JaTEne7mHh8ZgvrUUtOWZ/5PiutizAlmNmk/TF\nEqstjnn1FrVZYleLxUQnIM2ZPFW9poociWmNI7FrcWECBcx0uYColrIGx2I640jsWiwxChjvxKyt\nBU+Os/UoGI7liI4AQKYS43QiBYwjsdrKGSwxnXE68VociVHA7BKHYrVSsSwu7NBcnSPHHjiWGIWG\nXeTHaq2ULEt0BAqQaZhIOknRMQDIVGLxuOgEpDk7zxKrlaIlz0cLVV9dpE6aEzvkSAEAKfmP0SG1\n2fmy6AihUTL5/FFn9dF60REuk6fEeIAtBcxwPVjgNFct5FliWktF5Rl0yFNi9fU8CJgCZ3s8GaYW\n8tzPoDWOxG7EsoA6OVa7kL7sijxveZ1lPT5/1BlL7GY4pUgBcwqiE4RDjqd1aK053iw6wmUsMQoV\nJ8cNuLWQARfR6CpiRtAYaxQd4zKWGIWKkymJjqC9UiSCEg//1VZrolV0hKuwxChUzIqHCHh/XZAy\nNleA6owlditNTaITUAg4ZX7IBikdketjhaqrra5NdISryPVuS6V4EDAFzilyK0eQpk0+D9MZR2K3\n094uOgFpzsly5VxgDGDK43NHXTmWI9WiDkDGEuvoEJ2ANBdNF2BK+NbXQS7ioMJFHdpakVwhOsJ1\n5PtOZolRwAwPiLpyXOinm4UInzfqrLu+W3SE68hXYm1tPH6KAhfL8z0WhFl2mNa66rtER7iOfCUW\niXCVIgUuNs/FB0GYNPg8TFdJJynd8zBAxhIDuLiDAudkSjzRvspc08ScwR8OdNWVkm8UBshaYnwu\nRjUQq/C5WDXlHH49dSbj8zBA1hLrkrPxSS/xjOgEeuEmZ30ZMKR8HgbIWmLJJNAszynJpKf4dB4G\nuMCjWiZNHq6sq676LsRsOQ+ikLPEAKC3V3QC0pzpeohX5PzGVE3FsnARvOdGVwNNA6Ij3BRLjEIt\nwSnFqpiLOfA4qNWSaZjoa+wTHeOm5C2xjg6eo0iB45RidVy0eUqHrrrruxG1o6Jj3JS8JWYYQLec\nq2FIH5xSvHOuaeKCkRcdgwIi81QiIHOJAcCqVaITUAjUzXMUcSfSsSh4pLKeLMOSeioRkL3EenoA\nU+6IpL74VB4WbNExlDUa4Q8Buupv6kfEkvsSWbkbwnGAFfKdmkx6MQAkC9youxyeaWKEqxK1dVf7\nXaIj3JbcJQYAa9eKTkAhkJwocHnHMqRjUV69oqnWRCva6+Q/AlD+Euvv9w8FJgqQXagg7nKBx1KN\n8ltTW3e1yT8KA1QoMdv2i4woYMlZ0QnU4pkGRrgqUUtRK4qBZrlXJV4if4kBwPr1ohNQCMRn8rC5\nwGPR5qNRlMGpRB2tb10P21Tje0GNEuvsBOrrRaegEGjIcH5ssUYjfIqoIwMGNrVtEh1j0dQoMQBY\nt050AgqBuvEcR2OLULEsnDVzomNQANY0r0F9VJ1Bg1olZvAnPwqW4QH1CxyN3c5YwuEGZw0ZMLB1\nxVbRMZZEnRJLJnnPGNVEcjzPW59vxQCGrKLoFBSAgeYBNMQaRMdYEnVKDADuuUd0AgoBw/VQn5P3\nwFPRZuNxZMG7w3Sj4igMUK3Eenp4WSbVRHI0x9HYTZx2WGA6GmgeQGOsUXSMJVOrxABg82bRCSgE\nTNdDfZajsWvlow7GwalE3ag6CgNULLE1a/znY0QBS41muVLxGmdj6n1k0O2tb12v5CgMULHETBO4\n+27RKSgEDA9ommOJXVKMRHAWPKFDN47l4IGVD4iOsWzqlRgAbNzon3BPFLDEZB4xj9OKADASt+Fx\nl4t27u28F/FIXHSMZVOzxCIRYJM6O8pJbU3jPFqpYlkY4uZm7TREG7C5Q+11BmqWGOBPKVpcPUbB\nczJFpErq/qRaDRfqeHuzjrb1bINpqFsDgMollkhw3xjVTOOFQmiX3FcsCycMjsJ009fYh56GHtEx\n7pi6JQYA994LxHgHFAXPLLtong3ncVRnkg5KvPhSK47lYEfvDtExqkLtEnMcYKuaextIPYmpPOoq\n4ZpWzEcdnOQoTDvbe7YjEUmIjlEVapcY4C/waFDrrC9SV9P5cE0rHgtXZ4dCX2Mf1rasFR2jatQv\nMdMEPv950SkoJKySi6a5cGzvmE3EeTqHZmJ2DI/0PiI6RlWpX2IAsHo10NEhOgWFRN1kDgnNpxU9\n08BhhwWmm+0925XeE3YjepQYADz0kOgEFCItIwWtj6S6UMeT6nXT39SPgeYB0TGqTp8S6+gABvT7\nfxDJySy7aBs3YUC/IyzKto1j3NislYZoAx5d9ajoGIHQp8QA4OGHeRwV1YwzX0TTgn5bPIbqbFS4\npF4btmlj18AuOJaen416lVgiATz4oOgUFCKpUb2ej2VjUZwxeMivTh7pfQTNcX3vYdSrxAD/cODO\nTtEpKER0ej72SYyHS+lkU9smrZbT34h+JQYAjz7KcxWpZsyyi7ZRA6bi307jyQSmURIdg6qkva4d\n23q2iY4ROLW/626msRG4/37RKShEnIUSWqcjyi7zKDgOPrKzomNQldRF6rCrf5fyh/suhr7/hZs3\nA+3tolNQiMRnCmjOqPd8zDMNfBj3eEq9JhzLwVNrn0KdUyc6Sk3oW2KGAXzhC5xWpJpKjuVQX1Tr\nTLpTqRjmDE4j6sA0THxx4ItaL+S4lr4lBvjTitv0nxMmuTQNZ5VZsTibiPOAX4083vc4VqZWio5R\nU3qXGOCvVlyzRnQKCpnWc3nEvKjoGLdUitj40CmIjkFV8lD3Q1qeyHE7+pcYADzyiD8qI6oRw/XQ\ndqYob5EZwJE6E0U+CdPC5o7N2NyxWXQMIcJRYpEI8MQTgK3HXh5Sg+l6aDtbRFTCIhtJJnhCvSY2\nd2zGQ93hPTs2HCUGAM3NwA49bjIldZgVD+3nSoh68hz5sxCL4ROLy+l1sKVjS6gLDAhTiQHAunXA\n+vWiU1DImGUX7efKcCC+yCqWhYMxrkTUwb2d9+LBbh6zF64SA4Dt2/1RGVENXSoy0VOLnyYjvGJF\nA/d13ofPd/EyYCCMJWbbwJe+BMTVWAJN+rBKLtpPF5BwxZx8f6Y+jhEe7qu8+1fejwe6HhAdQxqG\n53nhvHNhchJ48UWgXBadhELGAzC9Ko6MXbv9WRdTCXzM52BKMw0Tj616TPsDfZcqvCUGAOfOAa+9\nBoT4S0DizHbFMRcLvsim6+L4IMINzSpzLAdfHPhi6DYyL0a4SwwAjh0D3nlHdAoKqUxHHNPJHIL6\nJpyPx7DXycNT9WRiQspJ4am1T6Exxr2uN8ISA4B9+4BDh0SnoJDKN0Qx2VpGpcoLLnLRKN6LF1EO\nrCIpaG2JNjy55knEI3yGfzMssUt++1vg5EnRKSikKlELE102CkZ1joEqRiJ4L1FBweCJHKra0LoB\n23u2wzJ5iPmtsMQucV3glVeA8+dFJ6GQ8gxgpieO+Tt8flW2bPwhBWTARUsqsk0bj/Q+wgUci8QS\nu1K57C/0YJGRQJn2OKZTeXjLmAZ0TRMH6i3e0KyoplgTdg3s4vOvJWCJXatcBl5/HRgZEZ2EQqxY\nF8FUp4HiEs439AwDHzc4GAVPplfRupZ12NG7A7bJM16XgiV2I5WKX2TDw6KTUIh5BjDXlUA6mr3t\nmMwzDRxLRTHMzczKiVpRbOvZxunDZWKJ3UylArzxhr+XjEigQr2DqTYPpZtMEbqmiSOpCC5WaVEI\n1c7qxtXY0buDqw/vAEvsVlzXL7KzZ0UnoZBzTQOz3bHrFn1ULAuHUhYmea2KUmJ2DDt6d6C/qV90\nFOWxxG7HdYE33wTOnBGdhAgjJrt1AAAIZElEQVSFhiimWz0UUUTZtnEgaWCWiziUMtA0gO292xGz\nxZyhqRuW2GJ4HrB3L3DkiOgkRPAApNe24Y2mDKYrPE5KFY2xRjzc/TB6GnpER9EKS2wpjhzxy4xf\nMhKpsxP40peQM13sO78Px6eOi05Et+BYDrau2Iq72++GaYTv4pCgscSW6tw54De/AUqcwiEB+vuB\nxx8HrM9OcZhYmMC+8/twfp77G2ViGiY2tW3C1hVbOXUYIJbYckxNAa++CiwsiE5CYbJlC/DgzW/y\nvTh/Efsv7MfFzMUahqJrGTDQ39SP+1fej4ZYg+g42mOJLVc26xfZ5KToJKS7SAR47DF/FLYI59Pn\nsf/CfowtjAUcjK5kGibWNK/BfZ33sbxqiCV2J8pl4O23gVOnRCchXTU1Abt2AY1LP4ZoeG4YH45+\niNHMaADB6BLLsLC+dT22dGxBKpoSHSd0WGLVcPSov+CjUt2rNCjkBgb8EZh9Z8cQTWYncWT8CIam\nh1Dx+B6tlqgVxfrW9djcsRmJSEJ0nNBiiVXL9LS/n2x2VnQSUp1pAg89BNx9d1V/21wph2OTx3B0\n4iiypWxVf+8w6ajrwMa2jRhoGuA1KRJgiVVTuQz8/vfAcS55pmVKJIAnnvCX0QfE9VycnjmNE9Mn\nMJIegevxzrHbcSwHa5vXYmPbRjTHm0XHoSuwxIJw8iTwzjtchk9LMzAAbN8OxGq3HDtfzuPUzCmc\nnD7JZ2fXsAwLPQ096G/qR19jH0+XlxRLLChzc/5t0RMTopOQ7OJxYMcOYPVqoTHmC/MYmhnCqZlT\nmMyGc9WtbdroqfeLq7ehFxErIjoS3QZLLEieBxw+DOzf7081El1LwOhrMXKlHIbTwxhJj2AkPYJ8\nWd8rXuqj9ViZWonu+m70NvRyxKUYllgtzM8D777L+8noM5KMvhbD8zxMZCcwPDeM0cwoJrITKFbU\nPTW/LlKHlamV6KrvwsrUSiSdpOhIdAdYYrU0NAS89x6Q46GtoSbp6GspZvOzGF8Yx/jCOCYWJjCV\nm5JygUgikkBLvAUtiRa0JlrRmmhFfbRedCyqIpZYrRUKwB/+AHz6qegkVGvNzcDDDwNdXaKTVF3F\nrSBdSGOuMOf/mp+7/NeZYibQPztiRpCKppB0kkg6SaScFJrjzWhJtHD/VgiwxES5eNHfIM1jq/QX\njwMPPACsXw8Yhug0NVdxK8iVc8iX89e9CuUCym4Zrudefl0pYkUQMSNwLAcRy//10isRSSDlpBC1\no4L+y0gGLDHRhoaADz4A0mnRSajaLAu45x7g3nsBxxGdhkhLLDEZuK4/vXjgAJ+X6aK/3z9xPsWz\n9IiCxBKTSbkMfPyx/yqqu/or1Hp6gK1bgY4O0UmIQoElJqN8HvjwQ+DYMe4vU4Fh+Evl770XaG0V\nnYYoVFhiMsvn/RPyjxzx/5rkYprA2rX+ZZXLuCqFiO4cS0wF5TIwOOiXGU/JF8+2gQ0bgM2bgSQ3\nyhKJxBJTzciIX2bnzolOEj5NTX55rV2r9EZlIp2wxFQ1N+ePzk6cADLBbiYNNdv2T9jYsIGLNYgk\nxBLTwcWLfpmdOsVVjdXS3u4X18AAEOFJ5kSyYonppFIBzp71C2142N9/RovX0gL09fkrDZt58SGR\nClhiusrn/UIbHvafo3GEdj3T9G9Q7usDVq3ixmQiBbHEwsDzgLExv8yGh8N9UWckAnR3+8XV2wtE\nee4ekcpYYmGUz/uFNjLil9vcnOhEwamr80dbnZ3+woyWllAewkukK5YY+VONExNXv1Rc8Wia/qbj\nS6XV2cl9XIrauXMnxsbGYJomACCRSGDjxo34/ve/j/vvv19wOpIJS4xuLJfzy2xqyj9hf37e/3Vh\nwZ+eFMmygIYGoL7e37vV1OQvxGhs9IuMlLdz5058+9vfxvPPPw8AmJ+fx09+8hO88MIL2Lt3L+Lx\nuOCEJAtbdACSVDzuPzPq7b36n7uuP0pLpz8rt2zWH83d6LWUwnMcfxNxPO6/rv3rRMIvLo6uQieV\nSuHZZ5/Fz372M4yOjmL16tWiI5EkWGK0NKbpF0n9Iq94L5U+KzPD8P/3hvHZ69LfX/qV6Aamp6fx\n05/+FPfddx9WrVolOg5JhNOJRCSda5+JFYtF9Pb24sc//jE2b94sOB3JhA8QiEhKP/zhD3H48GEc\nPnwYhw4dwve//3185zvfwf79+0VHI4mwxIhIevF4HF/96lexY8cO/PznPxcdhyTCEiMipeR5tx5d\ngSVGRNIrl8t46623sGfPHnzjG98QHYckwoUdRCSdaxd22LaNvr4+PP/883jmmWcEpyOZsMSIiEhZ\nnE4kIiJlscSIiEhZLDEiIlIWS4yIiJTFEiMiImWxxCgQZ86cwYYNG/DNb35TdBQi0hhLjAKxe/du\n7Nq1C4ODg/j0009FxyEiTbHEqOqKxSJ+8Ytf4Nlnn8UXvvAF7N69W3QkItIUS4yq7vXXX4dt29i+\nfTu+9rWv4aWXXkIulxMdi4g0xBKjqtu9eze+8pWvwLIsPProo4hGo/j1r38tOhYRaYglRlU1NDSE\nffv24etf/zoA/8y7L3/5y3jhhRcEJyMiHdmiA5BeLj3/eu655y7/s3K5jGKxiMHBQaxbt05UNCLS\nEA8ApqopFAp49NFH8b3vfQ9PPvnkVf/uBz/4AbZu3Yof/ehHgtIRkY44nUhV88orr6BQKOBb3/oW\nVq1addXrueeew4svvohCoSA6JhFphCVGVbN792489dRTSKVS1/27Z555BqVSCa+88oqAZESkK04n\nEhGRsjgSIyIiZbHEiIhIWSwxIiJSFkuMiIiUxRIjIiJlscSIiEhZLDEiIlIWS4yIiJTFEiMiImWx\nxIiISFn/H6CFJPx9gio9AAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f6163d4da90>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"Azw4kZkLxi1K","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"dd0add2f-6161-4694-bafe-76583e710174","executionInfo":{"status":"ok","timestamp":1523619083834,"user_tz":-540,"elapsed":753,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"metadata":{"id":"5WuWSfUy1wLv","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":370},"outputId":"52299e36-904c-4b47-dd65-a7010285c1eb","executionInfo":{"status":"error","timestamp":1523635825317,"user_tz":-540,"elapsed":5501,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once per notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Download a file based on its file ID.\n","#\n","# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n","file_id = '1FkR7onNyR5z5ko6mY8wtKoJ4L-DkUlfW'\n","downloaded = drive.CreateFile({'id': file_id})\n","\n","\n","#DeepDream 학습된 Neural Networks의 Feature를 시각화하고 이를 Input 이미지와 결합하며 환걱적인 이미지를 만들어 내는 알고리즘\n","#GoogLeNet Neural Networks 구조를 사용할거임.\n","\n","#라이브러리 Import\n","from __future__ import print_function\n","import os\n","\n","from io import BytesIO\n","import numpy as np\n","from functools import partial\n","import PIL.Image\n","from IPython.display import clear_output, Image, display, HTML\n","\n","import tensorflow as tf\n","\n","#미리 합습된 GoogLeNet graph 파일 다운로드 하고 이를 로드\n","print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n","\n","model_fn = downloaded.GetContentString()\n","\n","# TensorFlow session 구현 및 model 로드\n","graph = tf.Graph()\n","sess = tf.InteractiveSession(graph=graph)\n","\n","with tf.gfile.FastGFile(model_fn, 'rb') as f:\n","    graph_def = tf.GraphDef()\n","    graph_def.ParseFromString(f.read())\n","t_input = tf.placeholder(np.float32, name='input')   # input tensor 정의\n","imagenet_mean = 117.0\n","t_preprocessed = tf.expand_dims(t_input-imagenet_mean,0)\n","tf.import_graph_def(graph_def, {'input':t_preprocessed})\n","\n","# Newral Networks가 이미지 인식을 위해 학습한 내용을 훑어보기 위해서 단순하게, Neural Netwoks의 특정\n","#Convolution layer의 특정 채널의 Activation이 최대가 되는 값을 이용해서 이미지를 생성.\n","\n","layers = [op.name for op in graph.get_operations() if op.type == 'Conv2D' and 'import/' in op.name]\n","feature_nums = [int(graph.get_tensor_by_name(name + ':0').get_shape()[-1]) for name in layers]\n","\n","print('Number of layers', len(layers))\n","print('Total number of feature channels:', sum(feature_nums))\n","\n","\n","# Helper functions for TF Graph visualization\n","\n","def strip_consts(graph_def, max_const_size=32):\n","    \"\"\"Strip large constant values from graph_def.\"\"\"\n","    strip_def = tf.GraphDef()\n","    for n0 in graph_def.node:\n","        n = strip_def.node.add()\n","        n.MergeFrom(n0)\n","        if n.op == 'Const':\n","            tensor = n.attr['value'].tensor\n","            size = len(tensor.tensor_content)\n","            if size > max_const_size:\n","                tensor.tensor_content = bytes(\"<stripped %d bytes>\" % size)\n","    return strip_def\n","\n","\n","def rename_nodes(graph_def, rename_func):\n","    res_def = tf.GraphDef()\n","    for n0 in graph_def.node:\n","        n = res_def.node.add()\n","        n.MergeFrom(n0)\n","        n.name = rename_func(n.name)\n","        for i, s in enumerate(n.input):\n","            n.input[i] = rename_func(s) if s[0] != '^' else '^' + rename_func(s[1:])\n","    return res_def\n","\n","\n","def show_graph(graph_def, max_const_size=32):\n","    \"\"\"Visualize TensorFlow graph.\"\"\"\n","    if hasattr(graph_def, 'as_graph_def'):\n","        graph_def = graph_def.as_graph_def()\n","    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n","    code = \"\"\"\n","        <script>\n","          function load() {{\n","            document.getElementById(\"{id}\").pbtxt = {data};\n","          }}\n","        </script>\n","        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n","        <div style=\"height:600px\">\n","          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n","        </div>\n","    \"\"\".format(data=repr(str(strip_def)), id='graph' + str(np.random.rand()))\n","\n","    iframe = \"\"\"\n","        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n","    \"\"\".format(code.replace('\"', '&quot;'))\n","    display(HTML(iframe))\n","\n","\n","# Visualizing the network graph. Be sure expand the \"mixed\" nodes to see their\n","# internal structure. We are going to visualize \"Conv2D\" nodes.\n","tmp_def = rename_nodes(graph_def, lambda s: \"/\".join(s.split('_', 1)))\n","show_graph(tmp_def)\n","\n","#navie한 방법으로 feature들을 시각화\n","\n","# Picking some internal layer. Note that we use outputs before applying the ReLU nonlinearity\n","# to have non-zero gradients for features with negative initial activations.\n","layer = 'mixed4d_3x3_bottleneck_pre_relu'\n","channel = 139  # picking some feature channel to visualize\n","\n","# start with a gray image with a little noise\n","img_noise = np.random.uniform(size=(224, 224, 3)) + 100.0\n","\n","\n","def showarray(a, fmt='jpeg'):\n","    a = np.uint8(np.clip(a, 0, 1) * 255)\n","    f = BytesIO()\n","    PIL.Image.fromarray(a).save(f, fmt)\n","    display(Image(data=f.getvalue()))\n","\n","\n","def visstd(a, s=0.1):\n","    '''Normalize the image range for visualization'''\n","    return (a - a.mean()) / max(a.std(), 1e-4) * s + 0.5\n","\n","\n","def T(layer):\n","    '''Helper for getting layer output tensor'''\n","    return graph.get_tensor_by_name(\"import/%s:0\" % layer)\n","\n","\n","def render_naive(t_obj, img0=img_noise, iter_n=20, step=1.0):\n","    t_score = tf.reduce_mean(t_obj)  # defining the optimization objective\n","    t_grad = tf.gradients(t_score, t_input)[0]  # behold the power of automatic differentiation!\n","\n","    img = img0.copy()\n","    for i in range(iter_n):\n","        g, score = sess.run([t_grad, t_score], {t_input: img})\n","        # normalizing the gradient, so the same step size should work\n","        g /= g.std() + 1e-8  # for different layers and networks\n","        img += g * step\n","        print(score, end=' ')\n","    clear_output()\n","    showarray(visstd(img))\n","\n","\n","render_naive(T(layer)[:, :, :, channel])"],"execution_count":5,"outputs":[{"output_type":"error","ename":"UnicodeDecodeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-753ce5610714>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m#미리 합습된 GoogLeNet graph 파일 다운로드 하고 이를 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloaded content \"{}\"'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mmodel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetContentString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydrive/files.py\u001b[0m in \u001b[0;36mGetContentString\u001b[0;34m(self, mimetype, encoding, remove_bom)\u001b[0m\n\u001b[1;32m    192\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_bom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchContent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmimetype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mGetContentFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmimetype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove_bom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc0 in position 0: invalid start byte"]}]},{"metadata":{"id":"K6cVLwiJ4VPm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once per notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once per notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Download a file based on its file ID.\n","#\n","# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n","file_id = 'REPLACE_WITH_YOUR_FILE_ID'\n","downloaded = drive.CreateFile({'id': file_id})\n","print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1NxoKF8stM38","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":76},"outputId":"bbbd7b7d-d5eb-4073-a308-b400813cdb24","executionInfo":{"status":"ok","timestamp":1523786676980,"user_tz":-540,"elapsed":6306,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","\n"],"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-ccf844d8-19eb-4e80-9370-0a792e9d629a\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-ccf844d8-19eb-4e80-9370-0a792e9d629a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving 12.png to 12 (1).png\n"],"name":"stdout"}]},{"metadata":{"id":"7NwCk9Nrt5Q_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"387d7abb-52c5-4cef-816a-5ed75a83d0f3","executionInfo":{"status":"ok","timestamp":1523786683821,"user_tz":-540,"elapsed":777,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["User uploaded file \"12.png\" with length 4181 bytes\n"],"name":"stdout"}]},{"metadata":{"id":"jsMgRSaDuCKo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import pandas as pd\n","import io\n","df = pd.read_csv(io.StringIO(uploaded['iris.csv'].decode('utf-8')))\n","print(df)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"z0l3gDvNxuSd","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":143},"outputId":"2bb062ed-d4e4-44be-c901-4cca0ba755f9","executionInfo":{"status":"ok","timestamp":1523787382588,"user_tz":-540,"elapsed":279599,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":9,"outputs":[{"output_type":"stream","text":["gpg: keybox '/tmp/tmpw0mj2vzz/pubring.gpg' created\n","gpg: /tmp/tmpw0mj2vzz/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","··········\n"],"name":"stdout"}]},{"metadata":{"id":"t8grqc3u1t7w","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!mkdir -p colabData\n","!google-drive-ocamlfuse colabData"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cuzWs5V-1zig","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":557},"outputId":"50181a7f-dcd7-4c34-d4bc-1643c5b37fa5","executionInfo":{"status":"ok","timestamp":1523788231886,"user_tz":-540,"elapsed":1057,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["%%bash\n","echo \"Hello World...!!!\" > colabData/hello.txt\n","ls colabData\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["ㄴ\n","소왓 제출물\n","캡스톤\n","정보처리 기사 공부\n","자바스터디\n","곽승혁(01022403237).xlsx\n","프로젝트 - 열 차트 1.ods\n","프로젝트 - 막대 그래프 1.ods\n","2017학년도 창업소모임 팀원변경신청서.hwp\n","2018학년도 1학기 캡스톤디자인 과제 지원 신청서(곽승혁).hwp\n","algo\n","azk.zip\n","Copy of Monthly Calendar - Landscape.ods\n","Copy of Monthly Calendar - Landscape.ods (70b44221)\n","football-web .zip\n","hello.txt\n","IMG_5628.JPG\n","IMG_5629.JPG\n","이력서사진(곽승혁).jpg\n","KakaoTalk_20171123_222436445.jpg\n","KakaoTalk_20171123_222436445.odt\n","mb3-setup-consumer-3.1.2.1733-1.0.141-1.0.2092.exe\n","mzk.zip\n","제본 완료 보고 .odt\n","여수 여행 기획서.odt\n","티스토리 이미지.odt\n","소프트웨어 제본.odt\n","시스템구성도.odt\n","사업계획서_참고자료.pdf\n","새파일.txt\n"],"name":"stdout"}]},{"metadata":{"id":"0uMGUfGe2IHq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["f = open(\"colabData/새파일.txt\", 'w')\n","f.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2kw60SIZvlmR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":631},"outputId":"6bbbb54a-0903-40e2-bc2c-84bb0969e3da","executionInfo":{"status":"ok","timestamp":1523788684590,"user_tz":-540,"elapsed":215632,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["from __future__ import print_function\n","\n","import time\n","from PIL import Image\n","import numpy as np\n","\n","from keras import backend\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.vgg16 import preprocess_input\n","\n","from scipy.optimize import fmin_l_bfgs_b\n","from scipy.misc import imsave\n","\n","height = 512\n","width = 512\n","\n","##################################################\n","\n","#        DEFINING LOSS AND OTHER FUNCTIONS       #\n","\n","##################################################\n","\n","def content_loss(content, combination):\n","    return backend.sum(backend.square(combination-content))\n","\n","def gram_matrix(x):\n","    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n","    gram = backend.dot(features, backend.transpose(features))\n","    return gram\n","\n","def style_loss(style, combination):\n","    S = gram_matrix(style)\n","    C = gram_matrix(combination)\n","    channels = 3\n","    size = height * width\n","    return backend.sum(backend.square(S-C))/(4.*(channels**2)*(size**2))\n","\n","def total_variation_loss(x):\n","    a = backend.square(x[:, :height-1, :width-1, :] - x[:, 1:, :width-1, :])\n","    b = backend.square(x[:, :height-1, :width-1, :] - x[:, :height-1, 1:, :])\n","    return backend.sum(backend.pow(a+b, 1.25))\n","\n","def eval_loss_and_grads(x):\n","    x = x.reshape((1, height, width, 3))\n","    outs = f_outputs([x])\n","    loss_value = outs[0]\n","    grad_values = outs[1].flatten().astype('float64')\n","    return loss_value, grad_values\n","\n","def postprocess_array(x):\n","    x = x.reshape((height, width, 3))\n","    x[:, :, 0] += 103.939\n","    x[:, :, 1] += 116.779\n","    x[:, :, 2] += 123.68\n","    x = x[:, :, ::-1]\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x\n","\n","##################################################\n","\n","#           PREPROCESSING INPUT IMAGES           #\n","\n","##################################################\n","\n","content_image_path = 'colabData/background.jpg'\n","content_image = Image.open(content_image_path)\n","og_size = content_image.size\n","content_image = content_image.resize((width, height))\n","\n","style_image_path = 'colabData/vangogh.jpg'\n","style_image = Image.open(style_image_path)\n","style_image = style_image.resize((width, height))\n","\n","content_array = np.asarray(content_image, dtype='float32')\n","content_array = np.expand_dims(content_array, axis=0)\n","\n","style_array = np.asarray(style_image, dtype='float32')\n","style_array = np.expand_dims(style_array, axis=0)\n","\n","#preparation for vgg use\n","\n","content_array = preprocess_input(content_array)\n","style_array = preprocess_input(style_array)\n","\n","content_image = backend.variable(content_array)\n","style_image = backend.variable(style_array)\n","combination_image = backend.placeholder((1, height, width, 3))\n","\n","input_tensor = backend.concatenate([content_image, style_image, combination_image], axis=0)\n","\n","model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n","\n","##################################################\n","\n","#            TUNING THE HYPERPARAMETERS          #\n","\n","##################################################\n","\n","layers = dict([(layer.name, layer.output) for layer in model.layers])\n","\n","content_weight = 0.05\n","style_weight = 7.0\n","total_variation_weight = 1.0\n","\n","layer_features = layers['block2_conv2']\n","content_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","\n","loss = backend.variable(0.)\n","\n","loss += content_weight * content_loss(content_image_features, combination_features)\n","\n","feature_layers = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']\n","\n","for layer_name in feature_layers:\n","    layer_features = layers[layer_name]\n","    style_features = layer_features[1, :, :, :]\n","    combination_features = layer_features[2, :, :, :]\n","    sl = style_loss(style_features, combination_features)\n","    loss += (style_weight/len(feature_layers)) * sl\n","\n","loss += total_variation_weight * total_variation_loss(combination_image)\n","\n","grads = backend.gradients(loss, combination_image)\n","\n","outputs = [loss]\n","outputs += grads\n","f_outputs = backend.function([combination_image], outputs)\n","\n","class Evaluator(object):\n","\n","    def __init__(self):\n","        self.loss_value = None\n","        self.grads_values = None\n","\n","    def loss(self, x):\n","        assert self.loss_value is None\n","        loss_value, grad_values = eval_loss_and_grads(x)\n","        self.loss_value = loss_value\n","        self.grad_values = grad_values\n","        return self.loss_value\n","\n","    def grads(self, x):\n","        assert self.loss_value is not None\n","        grad_values = np.copy(self.grad_values)\n","        self.loss_value = None\n","        self.grad_values = None\n","        return grad_values\n","\n","evaluator = Evaluator()\n","\n","x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n","\n","iterations = 10\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    end_time = time.time()\n","    print('Iteration %d completed in %ds' % (i, end_time-start_time))\n","\n","    x = postprocess_array(x)\n","\n","    res = Image.fromarray(x)\n","    res = res.resize(og_size)\n","    save_path = 'colabData/iter' + str(i) + '.jpg'\n","    res.save(save_path)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 1s 0us/step\n","WARNING:tensorflow:Variable += will be deprecated. Use variable.assign_add if you want assignment to the variable value or 'x = x + y' if you want a new python Tensor object.\n","Start of iteration 0\n","Current loss value: 88446750000.0\n","Iteration 0 completed in 24s\n","Start of iteration 1\n","Current loss value: 111206020000.0\n","Iteration 1 completed in 19s\n","Start of iteration 2\n","Current loss value: 85900526000.0\n","Iteration 2 completed in 19s\n","Start of iteration 3\n","Current loss value: 83030475000.0\n","Iteration 3 completed in 19s\n","Start of iteration 4\n","Current loss value: 89773350000.0\n","Iteration 4 completed in 19s\n","Start of iteration 5\n","Current loss value: 65007227000.0\n","Iteration 5 completed in 19s\n","Start of iteration 6\n","Current loss value: 72197100000.0\n","Iteration 6 completed in 20s\n","Start of iteration 7\n","Current loss value: 66564200000.0\n","Iteration 7 completed in 19s\n","Start of iteration 8\n","Current loss value: 79977720000.0\n","Iteration 8 completed in 19s\n","Start of iteration 9\n","Current loss value: 84878780000.0\n","Iteration 9 completed in 19s\n"],"name":"stdout"}]},{"metadata":{"id":"Y4PmrxEV7npx","colab_type":"text"},"cell_type":"markdown","source":["2번째 style transfer"]},{"metadata":{"id":"OcbcTO_Q7qw5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":5471},"outputId":"5c488bba-4662-471d-da2d-cdc007606a2d","executionInfo":{"status":"ok","timestamp":1523799764794,"user_tz":-540,"elapsed":1999615,"user":{"displayName":"곽승혁","photoUrl":"//lh6.googleusercontent.com/-r5tKz864Re4/AAAAAAAAAAI/AAAAAAAAADA/znpDCmxx4VA/s50-c-k-no/photo.jpg","userId":"107783920520848395760"}}},"cell_type":"code","source":["\"\"\"Neural Style Transfer\"\"\"\n","# Importing all the required packages\n","from __future__ import print_function\n","from PIL import Image\n","import time\n","import numpy as np\n","import argparse\n","\n","from keras import backend\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","\n","from scipy.optimize import fmin_l_bfgs_b\n","from scipy.misc import imsave\n","\n","# Dimensions of the images\n","height = 512\n","width = 512\n","'''\n","# Passing image addresses as arguments\n","parser = argparse.ArgumentParser(description=\"Neural Style Transfer with Keras.\")\n","parser.add_argument('colabData/background.jpg', metavar='base', type=str, help='Path to the Content Image')\n","parser.add_argument('colabData/vangogh.jpg', metavar='ref',\n","                    type=str, help='Path to the Style Image')\n","args = parser.parse_args()\n","'''\n","# Import Images and Resize them\n","#content_image_path = args.content_image_path\n","content_image_path = 'colabData/ys.jpg'\n","content_image = Image.open(content_image_path)\n","content_image = content_image.resize((width, height))\n","\n","#style_image_path = args.style_image_path\n","style_image_path = 'colabData/이중섭.jpg'\n","style_image = Image.open(style_image_path)\n","style_image = style_image.resize((width, height))\n","\n","content_array = np.asarray(content_image, dtype='float32')\n","content_array = np.expand_dims(content_array, axis=0)\n","\n","style_array = np.asarray(style_image, dtype='float32')\n","style_array = np.expand_dims(style_array, axis=0)\n","\n","content_array[:, :, :, 0] -= 103.939\n","content_array[:, :, :, 1] -= 116.779\n","content_array[:, :, :, 2] -= 123.68\n","content_array = content_array[:, :, :, ::-1]\n","\n","style_array[:, :, :, 0] -= 103.939\n","style_array[:, :, :, 1] -= 116.779\n","style_array[:, :, :, 2] -= 123.68\n","style_array = style_array[:, :, :, ::-1]\n","\n","content_image = backend.variable(content_array)\n","style_image = backend.variable(style_array)\n","combination_image = backend.placeholder((1, height, width, 3))\n","\n","input_tensor = backend.concatenate([content_image, style_image, combination_image], axis=0)\n","\n","model = VGG16(input_tensor=input_tensor, weights='imagenet', include_top=False)\n","layers = dict([(layer.name, layer.output) for layer in model.layers])\n","# print(layers)\n","\n","content_weight = 0.025\n","style_weight = 9.0\n","total_variation_weight = 1.0\n","loss = backend.variable(0.)\n","\n","# Content Loss\n","\n","\n","def content_loss(content, combinaton):\n","    return backend.sum(backend.square(combinaton - content))\n","\n","\n","layer_features = layers['block2_conv2']\n","content_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","# Content loss appended to the loss variable\n","loss += content_weight * content_loss(content_image_features,\n","                                      combination_features)\n","\n","# Style Loss\n","\n","\n","def gram_matrix(x):\n","    features = backend.batch_flatten(backend.permute_dimensions(x, (2, 0, 1)))\n","    gram = backend.dot(features, backend.transpose(features))\n","    return gram\n","\n","\n","def style_loss(style, combinaton):\n","    S = gram_matrix(style)\n","    C = gram_matrix(combinaton)\n","    channels = 3\n","    size = width * height\n","    return backend.sum(backend.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n","\n","\n","feature_layers = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3', 'block5_conv3']\n","\n","for layer_name in feature_layers:\n","    layer_features = layers[layer_name]\n","    style_features = layer_features[1, :, :, :]\n","    combination_features = layer_features[2, :, :, :]\n","    sl = style_loss(style_features, combination_features)\n","    loss += (style_weight / len(feature_layers)) * sl\n","\n","# Total Variation Loss (Content + Style)\n","\n","\n","def total_variation_loss(x):\n","    a = backend.square(x[:, :height - 1, :width - 1, :] - x[:, 1:, :width - 1, :])\n","    b = backend.square(x[:, :height - 1, :width - 1, :] - x[:, :height - 1, 1:, :])\n","    return backend.sum(backend.pow(a + b, 1.25))\n","\n","\n","loss += total_variation_weight * total_variation_loss(combination_image)\n","\n","# Solving the optimisation problem\n","grads = backend.gradients(loss, combination_image)\n","\n","outputs = [loss]\n","outputs += grads\n","f_outputs = backend.function([combination_image], outputs)\n","\n","\n","def eval_loss_and_grads(x):\n","    x = x.reshape((1, height, width, 3))\n","    outs = f_outputs([x])\n","    loss_value = outs[0]\n","    grad_values = outs[1].flatten().astype('float64')\n","    return loss_value, grad_values\n","\n","\n","class Evaluator(object):\n","\n","    def __init__(self):\n","        self.loss_value = None\n","        self.grads_values = None\n","\n","    def loss(self, x):\n","        assert self.loss_value is None\n","        loss_value, grad_values = eval_loss_and_grads(x)\n","        self.loss_value = loss_value\n","        self.grad_values = grad_values\n","        return self.loss_value\n","\n","    def grads(self, x):\n","        assert self.loss_value is not None\n","        grad_values = np.copy(self.grad_values)\n","        self.loss_value = None\n","        self.grad_values = None\n","        return grad_values\n","\n","\n","evaluator = Evaluator()\n","\n","x = np.random.uniform(0, 255, (1, height, width, 3)) - 128.\n","\n","iterations = 101\n","\n","for i in range(iterations):\n","    print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    end_time = time.time()\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))\n","    if i % 10 == 0:\n","        # Deprocess the image\n","        x = x.reshape((height, width, 3))\n","        x = x[:, :, ::-1]\n","        x[:, :, 0] += 103.939\n","        x[:, :, 1] += 116.779\n","        x[:, :, 2] += 123.68\n","        x = np.clip(x, 0, 255).astype('uint8')\n","        img = Image.fromarray(x)\n","        img.save('colabData/캡스톤/resultys_%d.png' % (i))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Start of iteration 0\n","Current loss value: 204464650000.0\n","Iteration 0 completed in 19s\n","Start of iteration 1\n","Current loss value: 430024500000.0\n","Iteration 1 completed in 18s\n","Start of iteration 2\n","Current loss value: 95108300000.0\n","Iteration 2 completed in 19s\n","Start of iteration 3\n","Current loss value: 68752000000.0\n","Iteration 3 completed in 19s\n","Start of iteration 4\n","Current loss value: 55188250000.0\n","Iteration 4 completed in 19s\n","Start of iteration 5\n","Current loss value: 46640950000.0\n","Iteration 5 completed in 19s\n","Start of iteration 6\n","Current loss value: 41911886000.0\n","Iteration 6 completed in 19s\n","Start of iteration 7\n","Current loss value: 39099474000.0\n","Iteration 7 completed in 19s\n","Start of iteration 8\n","Current loss value: 37053633000.0\n","Iteration 8 completed in 19s\n","Start of iteration 9\n","Current loss value: 35698520000.0\n","Iteration 9 completed in 19s\n","Start of iteration 10\n","Current loss value: 34887135000.0\n","Iteration 10 completed in 19s\n","Start of iteration 11\n","Current loss value: 278997500000.0\n","Iteration 11 completed in 20s\n","Start of iteration 12\n","Current loss value: 74734920000.0\n","Iteration 12 completed in 19s\n","Start of iteration 13\n","Current loss value: 49169342000.0\n","Iteration 13 completed in 19s\n","Start of iteration 14\n","Current loss value: 41323418000.0\n","Iteration 14 completed in 19s\n","Start of iteration 15\n","Current loss value: 37958890000.0\n","Iteration 15 completed in 19s\n","Start of iteration 16\n","Current loss value: 36227203000.0\n","Iteration 16 completed in 19s\n","Start of iteration 17\n","Current loss value: 35302760000.0\n","Iteration 17 completed in 19s\n","Start of iteration 18\n","Current loss value: 34682140000.0\n","Iteration 18 completed in 19s\n","Start of iteration 19\n","Current loss value: 34281202000.0\n","Iteration 19 completed in 19s\n","Start of iteration 20\n","Current loss value: 34005199000.0\n","Iteration 20 completed in 19s\n","Start of iteration 21\n","Current loss value: 251291100000.0\n","Iteration 21 completed in 19s\n","Start of iteration 22\n","Current loss value: 61211540000.0\n","Iteration 22 completed in 19s\n","Start of iteration 23\n","Current loss value: 44721893000.0\n","Iteration 23 completed in 19s\n","Start of iteration 24\n","Current loss value: 39579492000.0\n","Iteration 24 completed in 19s\n","Start of iteration 25\n","Current loss value: 36680212000.0\n","Iteration 25 completed in 19s\n","Start of iteration 26\n","Current loss value: 35532930000.0\n","Iteration 26 completed in 19s\n","Start of iteration 27\n","Current loss value: 34808290000.0\n","Iteration 27 completed in 19s\n","Start of iteration 28\n","Current loss value: 34291118000.0\n","Iteration 28 completed in 19s\n","Start of iteration 29\n","Current loss value: 33932840000.0\n","Iteration 29 completed in 19s\n","Start of iteration 30\n","Current loss value: 33694590000.0\n","Iteration 30 completed in 19s\n","Start of iteration 31\n","Current loss value: 252928230000.0\n","Iteration 31 completed in 19s\n","Start of iteration 32\n","Current loss value: 75651600000.0\n","Iteration 32 completed in 19s\n","Start of iteration 33\n","Current loss value: 49942120000.0\n","Iteration 33 completed in 19s\n","Start of iteration 34\n","Current loss value: 41495160000.0\n","Iteration 34 completed in 19s\n","Start of iteration 35\n","Current loss value: 38452494000.0\n","Iteration 35 completed in 19s\n","Start of iteration 36\n","Current loss value: 36578435000.0\n","Iteration 36 completed in 19s\n","Start of iteration 37\n","Current loss value: 35416134000.0\n","Iteration 37 completed in 19s\n","Start of iteration 38\n","Current loss value: 34732155000.0\n","Iteration 38 completed in 20s\n","Start of iteration 39\n","Current loss value: 34322213000.0\n","Iteration 39 completed in 19s\n","Start of iteration 40\n","Current loss value: 34006184000.0\n","Iteration 40 completed in 20s\n","Start of iteration 41\n","Current loss value: 253416950000.0\n","Iteration 41 completed in 19s\n","Start of iteration 42\n","Current loss value: 67668443000.0\n","Iteration 42 completed in 19s\n","Start of iteration 43\n","Current loss value: 48282042000.0\n","Iteration 43 completed in 19s\n","Start of iteration 44\n","Current loss value: 41514900000.0\n","Iteration 44 completed in 19s\n","Start of iteration 45\n"],"name":"stdout"},{"output_type":"stream","text":["Current loss value: 37825835000.0\n","Iteration 45 completed in 19s\n","Start of iteration 46\n","Current loss value: 36129346000.0\n","Iteration 46 completed in 19s\n","Start of iteration 47\n","Current loss value: 35052330000.0\n","Iteration 47 completed in 19s\n","Start of iteration 48\n","Current loss value: 34524307000.0\n","Iteration 48 completed in 19s\n","Start of iteration 49\n","Current loss value: 34130172000.0\n","Iteration 49 completed in 19s\n","Start of iteration 50\n","Current loss value: 33883605000.0\n","Iteration 50 completed in 19s\n","Start of iteration 51\n","Current loss value: 267103960000.0\n","Iteration 51 completed in 19s\n","Start of iteration 52\n","Current loss value: 65590333000.0\n","Iteration 52 completed in 19s\n","Start of iteration 53\n","Current loss value: 46793190000.0\n","Iteration 53 completed in 19s\n","Start of iteration 54\n","Current loss value: 40641737000.0\n","Iteration 54 completed in 19s\n","Start of iteration 55\n","Current loss value: 37905633000.0\n","Iteration 55 completed in 20s\n","Start of iteration 56\n","Current loss value: 36214964000.0\n","Iteration 56 completed in 19s\n","Start of iteration 57\n","Current loss value: 35237950000.0\n","Iteration 57 completed in 19s\n","Start of iteration 58\n","Current loss value: 34666460000.0\n","Iteration 58 completed in 19s\n","Start of iteration 59\n","Current loss value: 34285908000.0\n","Iteration 59 completed in 19s\n","Start of iteration 60\n","Current loss value: 33949034000.0\n","Iteration 60 completed in 19s\n","Start of iteration 61\n","Current loss value: 257703540000.0\n","Iteration 61 completed in 19s\n","Start of iteration 62\n","Current loss value: 66234212000.0\n","Iteration 62 completed in 19s\n","Start of iteration 63\n","Current loss value: 45398060000.0\n","Iteration 63 completed in 19s\n","Start of iteration 64\n","Current loss value: 39283937000.0\n","Iteration 64 completed in 19s\n","Start of iteration 65\n","Current loss value: 36924980000.0\n","Iteration 65 completed in 19s\n","Start of iteration 66\n","Current loss value: 35564200000.0\n","Iteration 66 completed in 19s\n","Start of iteration 67\n","Current loss value: 34863320000.0\n","Iteration 67 completed in 19s\n","Start of iteration 68\n","Current loss value: 34331840000.0\n","Iteration 68 completed in 19s\n","Start of iteration 69\n","Current loss value: 34012207000.0\n","Iteration 69 completed in 19s\n","Start of iteration 70\n","Current loss value: 33786962000.0\n","Iteration 70 completed in 19s\n","Start of iteration 71\n","Current loss value: 269265450000.0\n","Iteration 71 completed in 19s\n","Start of iteration 72\n","Current loss value: 70758990000.0\n","Iteration 72 completed in 19s\n","Start of iteration 73\n","Current loss value: 46534087000.0\n","Iteration 73 completed in 19s\n","Start of iteration 74\n","Current loss value: 40058266000.0\n","Iteration 74 completed in 19s\n","Start of iteration 75\n","Current loss value: 37343076000.0\n","Iteration 75 completed in 19s\n","Start of iteration 76\n","Current loss value: 35990570000.0\n","Iteration 76 completed in 19s\n","Start of iteration 77\n","Current loss value: 35189740000.0\n","Iteration 77 completed in 19s\n","Start of iteration 78\n","Current loss value: 34544534000.0\n","Iteration 78 completed in 19s\n","Start of iteration 79\n","Current loss value: 34187600000.0\n","Iteration 79 completed in 19s\n","Start of iteration 80\n","Current loss value: 33945653000.0\n","Iteration 80 completed in 19s\n","Start of iteration 81\n","Current loss value: 265376810000.0\n","Iteration 81 completed in 19s\n","Start of iteration 82\n","Current loss value: 68143570000.0\n","Iteration 82 completed in 19s\n","Start of iteration 83\n","Current loss value: 48114483000.0\n","Iteration 83 completed in 19s\n","Start of iteration 84\n","Current loss value: 41047966000.0\n","Iteration 84 completed in 19s\n","Start of iteration 85\n","Current loss value: 38014783000.0\n","Iteration 85 completed in 19s\n","Start of iteration 86\n","Current loss value: 36352220000.0\n","Iteration 86 completed in 19s\n","Start of iteration 87\n","Current loss value: 35268420000.0\n","Iteration 87 completed in 19s\n","Start of iteration 88\n","Current loss value: 34592825000.0\n","Iteration 88 completed in 19s\n","Start of iteration 89\n","Current loss value: 34178937000.0\n","Iteration 89 completed in 19s\n","Start of iteration 90\n"],"name":"stdout"},{"output_type":"stream","text":["Current loss value: 33912189000.0\n","Iteration 90 completed in 19s\n","Start of iteration 91\n","Current loss value: 247247370000.0\n","Iteration 91 completed in 19s\n","Start of iteration 92\n","Current loss value: 78691660000.0\n","Iteration 92 completed in 19s\n","Start of iteration 93\n","Current loss value: 50248258000.0\n","Iteration 93 completed in 19s\n","Start of iteration 94\n","Current loss value: 41245130000.0\n","Iteration 94 completed in 19s\n","Start of iteration 95\n","Current loss value: 38444940000.0\n","Iteration 95 completed in 19s\n","Start of iteration 96\n","Current loss value: 36494512000.0\n","Iteration 96 completed in 19s\n","Start of iteration 97\n","Current loss value: 35576627000.0\n","Iteration 97 completed in 19s\n","Start of iteration 98\n","Current loss value: 34816745000.0\n","Iteration 98 completed in 19s\n","Start of iteration 99\n","Current loss value: 34356986000.0\n","Iteration 99 completed in 19s\n","Start of iteration 100\n","Current loss value: 34018568000.0\n","Iteration 100 completed in 19s\n"],"name":"stdout"}]}]}